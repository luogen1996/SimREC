# coding=utf-8
# Copyright 2022 The SimREC Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from datetime import timedelta

import torch
import torch.distributed as dist

from simrec.utils.metric import AverageMeter

_LOCAL_PROCESS_GROUP = None

def get_world_size():
    if not dist.is_available():
        return 1
    if not dist.is_initialized():
        return 1
    return dist.get_world_size()


def get_rank():
    if not dist.is_available():
        return 0
    if not dist.is_initialized():
        return 0
    return dist.get_rank()


def is_main_process():
    return get_rank() == 0


def get_local_size() -> int:
    """
    Returns:
        The size of the per-machine process group,
        i.e. the number of processes per machine.
    """
    if not dist.is_available():
        return 1
    if not dist.is_initialized():
        return 1
    return dist.get_world_size(group=_LOCAL_PROCESS_GROUP)


def synchronize():
    """
    Helper function to synchronize (barrier) among all processes when
    using distributed training
    """
    if not dist.is_available():
        return
    if not dist.is_initialized():
        return
    world_size = dist.get_world_size()
    if world_size == 1:
        return
    if dist.get_backend() == dist.Backend.NCCL:
        # This argument is needed to avoid warnings.
        # It's valid only for NCCL backend.
        dist.barrier(device_ids=[torch.cuda.current_device()])
    else:
        dist.barrier()


def setup_distributed(cfg, rank: int, backend: str = 'NCCL'):
    if not dist.is_available():
        raise ModuleNotFoundError('torch.distributed package not found')

    if cfg.train.ddp.world_size > len(cfg.train.gpus):
        assert '127.0.0.1' not in cfg.train.ddp.dist_url, "DIST_URL is illegal with multi nodes distributed training"

    dist.init_process_group(dist.Backend(backend), rank=rank, world_size=cfg.train.ddp.world_size, init_method=cfg.train.ddp.dist_url)

    if not dist.is_initialized():
        raise ValueError('init_process_group failed')


def cleanup_distributed():
    dist.destroy_process_group()


def reduce_meters(meters, rank, cfg):
    """Sync and flush meters."""
    assert isinstance(meters, dict), "collect AverageMeters into a dict"
    for name in sorted(meters.keys()):
        meter = meters[name]
        if not isinstance(meter, AverageMeter):
            raise TypeError("meter should be AverageMeter type")
        avg = torch.tensor(meter.avg).unsqueeze(0).to(rank)
        avg_reduce = [torch.ones_like(avg) for _ in range(dist.get_world_size())]
        dist.all_gather(avg_reduce, avg)
        if is_main_process():
            value = torch.mean(torch.cat(avg_reduce)).item()
            meter.update_reduce(value)

def find_free_port():
    import socket
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    # Binding to port 0 will cause the OS to find an available port for us
    sock.bind(("", 0))
    port = sock.getsockname()[1]
    sock.close()
    # NOTE: there is still a chance the port could be taken by other processes.
    return port
